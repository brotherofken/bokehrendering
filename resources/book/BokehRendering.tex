%*******************************************************************************
% Example chapter file for books, Copyright A K Peters, Ltd.
%*******************************************************************************
\chapter{Depth of Field with Bokeh Rendering}{Charles de Rousiers and Matt Pettineo}
\label{BokehRendering}

%-------------------------------------------------------------------------------
\section{Introduction}

In order to increase realism and immersion, current games make frequent use of depth of field to simulate lenticular phenomena. Typical implementations use screen-space filtering techniques to crudely approximate a camera’s circle of confusion for out-of-focus portions of a scene. While such approaches can provide pleasing results with minimal performance impact, crucial features present in real-life photography are still missing. In particular, lens-based cameras produce a phenomenon known as \bokeh (blur in Japanese). Bokeh manifests as distinctive geometric shapes that are most visible in out-of-focus portions of an image with high local contrast. The actual shape itself depends on the shape of the camera’s aperture, which is typically circular, octagonal, hexagonal, or pentagonal.

Current and upcoming DirectX 11 engines (i.e. CryENGINE, Unreal Engine 3, ...) have recently demonstrated new techniques for simulating bokeh depth of field, which reflects a rising interest in reproducing such effects in real-time. However, these techniques have performance requirements that can potentially relegate them to high-end GPU's. The precise implementation details of these techniques also aren't publicly available, making it potentially difficult to integrate these techniques into existing engines. Consequently it remains an active area of research, as there is still a need for implementations that are suitable for a wider range of hardware.

A naive approach would be to explicitly render a quad for each pixel, with each quad using a texture containing the aperture shape. While this can produce excellent results, it's also extremely inefficient due to the heavy fillrate and bandwidth requirements. Instead we propose an hybrid method, by mixing previous filtering-based approaches with quad rendering. Our method selects pixels with high local contrast, and renders a single textured quad for each such pixel. The texture used for the quad contains the camera's aperture shape, which allows the quads to approximate bokeh effects. In order to achieve high performance, we use atomic counters in conjunction with an image texture for random memory access. An indirect draw command is also used, which avoids the need for expensive CPU / GPU synchronization. This efficient OpenGL 4.2 implementation allows rendering of thousands of aperture-shape quads at high frame-rates, and also and ensures the temporal coherency of the rendered \bokeh.

%-------------------------------------------------------------------------------
\section{Depth of Field Phenomemon}\label{Derousiers:DOFPhenomenon}
Depth of field is an important effect to convey a realistic sense of depth and scale, particularly in open scenes with a large viewing distance. Traditional real-time applications use a pinhole camera model for rasterization, which results in an infinite depth of field. However real cameras use a thin lens, which introduces a limited depth of field based on aperture size and focal distance. Objects outside of this of this region appear blurred on the final image, while objects inside of it remain sharp. See Figure~\ref{DeRousiers:focus}.

	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{focus}
	\caption{Depth of field phenomenon, where a thin lens introduces a limited depth of field. In-focus objects appear sharp, while out-of-focus object appear blurred. The size of the circle of confusion depends on the distance beween object and the point at which the camera is focused. We use a linear approximation in order to simplify settings and computations. }
	\label{DeRousiers:focus}
	\end{figure}


The "blurriness" of an object is defined by its \emph{circle of confusion} (\coc). The size of this \coc depends on the distance between the object and the area at which the camera is focused. The further an object is from the focused area, the blurrier it appears. The size of the \coc does not increase linearly based on this distance. The size actually increases faster in the out-of-focus foreground area than it does the out-of-focus background area, see Figure~\ref{DeRousiers:focus}. Since the \coc size ultimately depends on focal distance, lens size, and aperture shape, setting up the simulation parameters may not be intuitive to someone inexperienced with photographics. This is why we use a simple linear approximation as proposed by~\cite{Hammon07}, see Figure~\ref{DeRousiers:focus}.

	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{camera}
	\caption{Aperture shape of a camera. Aperture blocks a portion of the incoming light. Its shape modifies the pixel integration, and hence, it changes the \bokeh shape. }
	\label{DeRousiers:camera}
	\end{figure}

The aperture of a camera is responsible for allowing light to pass through the lens and strike the sensor (or film)\footnote{If an object or the camera moves while the aperture is open, the objects will appear blurred. This is known as motion blur.}. The shape of this aperture directly impacts the formation of the image, since each point out-of-focus is convolved with the aperture shape. See Figure~\ref{DeRousiers:camera}.

While it is often difficult to see distinct \bokeh patterns in areas with low contrast, \bokehs are clearly visible in areas that are significantly brighter than their surroundings. We use this observation as an heuristic to determine where \bokeh quads need to be drawn in order to provide a plausible approximation.

%-------------------------------------------------------------------------------
\section{Relative Work}\label{Derousiers:RelativeWork}

Several methods have been proposed during the last decade for efficiently approximating a depth of field effect. However those methods use a Gaussian blur or heat diffusion to simulate out-of-focus areas~\cite{Hammon07,Kosloff07} and are therefore unable to reproduce \bokeh effects.

An earlier approach from Krivanek~\cite{Krivanek03} uses sprite splatting as a means for implementing depth of field, rather than a filtering approach. While this brute force method does produce \bokeh shapes, it is quite inefficient due to excessive overdraw and bandwidth consumption. The video games industry has shown a recent interest for \bokeh effects~\cite{Sousa11,Futurmark11,Mittring11}. While complete implementation details are not available, these methods largely take a similar approach Krivanek where sprites are rendered for each pixel. Consequently, these techniques make use of complex optimizations (hierarchical rasterization, multiple downscaling passes, ...) in order to improve performance. 

A recent approach proposed by White~\cite{White11} reproduces pentagonal \bokeh using several directional blur passes. While efficient, this method does not support arbitrary aperture shapes.

%-------------------------------------------------------------------------------
\section{Algorithm}
We observe that only high contrasted points produce distinct \bokehs. We use this heuristic to detect \bokeh positions in screen space~\cite{Pettineo11} and render final \bokehs by splatting textured quad at those locations. Every other points are rendered with a blur based approach.

\subsection{Overview}
Our approach is divide into four passes, see Figure~\ref{DeRousiers:pipeline}. The first pass computes the \coc size for each pixel based on its depth value and output a linear depth buffer\footnote{If you already have a linear depth buffer as input, you can merge together the first two passes.}. Then, the second pass computes the contrast of the current pixel. If this contrast is enough, its position, \coc size, and averaged color are append to a buffer. During the third pass, a blur-based depth of field is computed with one of the previous methods (Gaussian blur,...). Finally, the last pass splats textured quad at \bokeh positions.

	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{pipeline}
	\caption{Overview of the pipeline. It is composed of four passes and takes as input the color and depth buffers of the current frame. It outputs a final color image with depth of field and \bokeh effects.}
	\label{DeRousiers:pipeline}
	\end{figure}

In order to ensure high performances, CPU/GPU synchronization has to be avoided. We use an indirect draw command which read how many \bokeh has to be drawn from a GPU buffer. This way, the number of detected \bokehs is never read back by the CPU.

\subsection{Circles of confusion computation}
Set up field of view with focal length is not easy. We define two areas where geometry is out-of-focus : a near/foreground area and a far/background area. Both areas are delimited with a near and far depth values, see Figure~\ref{DeRousiers:focus}. Blur amount is linearly interpolated between those bounds. It allows a easy and intuitive way to set up field of view.

$$
	CoC = \frac{Z_{pixel} - Z_{start} }{ Z_{end} - Z_{start} }
$$

This way the \coc size is normalized between [0,1]. An extra parameter \codecmd{MaxRadius} determines a posteriori what is final size of the blur. This lets artists to play with, in order to achieve the desired appearance and also balances performances (lesser the \codecmd{MaxRadius} is, greater the performances are).


\subsection{\Bokeh detection}
This pass aims to detect pixels which will generate \bokehs. To detect them, we use the following heuristic : \emph{an highly contrasted pixel in a given neighborhood will generate a \bokeh}. We compare the current pixel luminance $L_{pixel}$ to its neighborhood luminance $L_{neigh}$. If the difference $L_{pixel}-L_{neigh}$ is greater than the threshold \codecmd{LumThreshold}, then the current pixel is registered as a \bokeh. Pixels detected as \bokeh are sparse. Storing them into a texture render target would be a waste of space and reading them back would be a waste of time due to their no-coherency in space. To address this problem, we use the \opengl \codecmd{ImageBuffers} in combination with an \codecmd{AtomicCounter}. This allows us to built a vector in which we append detected \bokehs parameters. \codecmd{ImageBuffers} have to be preallocated with a given size (\ie the maximum number of \bokehs which can be display on screen). The atomic counter \codecmd{BokehCounter} stores the number of appended \bokehs. Its current value indicates the next free cells in the \codecmd{ImageBuffers} vector. Two \codecmd{ImageBuffers} \codecmd{BokehPosition} and, \codecmd{BokehColor}, are used to store \coc size, position, and color of the registered \bokehs. 

	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{extraction}
	\caption{\Bokeh detection. The luminance the current pixel is compared to its neighborhood. If the difference is greater than \codecmd{LunThreshod}, \bokeh parameters (position, color, \coc) are appended into \codecmd{BokehPosition} and \codecmd{BokehColor} buffers and the atomic counter \codecmd{BokehCounter} is incremented.}
	\label{DeRousiers:detection}
	\end{figure}

\subsection{Blur-based depth of field}
Several approaches are possible for this pass. We refer readers to previous work for this step. Nevertheless, here a short sum up of main approaches :
\begin{itemize}
	\item Do a constant kernel Gaussian blur at various resolutions and apply a linear interpolation to blend them according to \coc size.
	\item Do a Poisson disc sampling with a radius adapted to \coc size~\footnote{A random rotation can be applied to a Poisson sampling pattern for transforming aliasing into noise.}.
	\item Do a large bilateral filtering and rejecting invalid pixel~\footnote{For implementation details, we refer the reader to the code sample. This approach offers a good compromise between quality and performances. However it need large radius. A \opencl implementation would allow better performances, since shared memory can be used to cache texture fetches.}.
\end{itemize}


\subsection{\Bokeh rendering}
In order to avoid CPU/GPU synchronization, we use the indirect drawing command \codecmd{glDrawArraysIndirect}. This command draw instances of a given VBO/VAO. The number of instance is specified into a buffer located on the GPU memory. This buffer can be updated from the CPU or from the GPU. For performances concerns, we update this buffer from the GPU during the second pass. The atomic counter, used in pass 2, is bound to this indirect buffer. Thus, the number of drawn instance is equal to the number of detected \bokeh.

We use this command in combination point VAO. The instanced points are translated into the vertex shader to be located at \bokeh position. The position is read from the \codecmd{BokehPosition} buffer by using the built-in \codecmd{gl\_InstanceID} index. Each point is expanded in a quad into the geometry shader. The size of the quad is adapted to \bokeh size (also store into the \codecmd{BokehPosition} buffer ). Finally, the fragment shader applies the \bokeh alpha-texture onto the quad and multiplies it by the \bokeh color (stored into the \codecmd{BokehColor} buffer).

%-------------------------------------------------------------------------------
\section{Results}

\subsection{Rendering}
	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{todo}
	\caption{Rendering 1.}
	\label{YourName:fig1}
	\end{figure}

	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{todo}
	\caption{Rendering 2.}
	\label{YourName:fig1}
	\end{figure}

\subsection{Performances}
	\begin{figure}[htb]\centering
	\includegraphics[width=\textwidth]{todo}
	\caption{Performances.}
	\label{YourName:fig1}
	\end{figure}

%-------------------------------------------------------------------------------
\section{Discussion}
One may concerns about temporal coherency for this approach. Just as all others methods, we base our approach on the final color buffer. If sub-pixel aliasing is handled properly by previous rendering steps, our approach is stable and \bokehs are coherent frame-to-frame. In case of sub-pixel aliasing, our method exhibits same limitations as all previous methods, and \bokehs may flicked.

Also, Our methods need preallocated buffers for storing \bokehs' position and color. Hence, a maximum number of \bokehs has to be specified. If this number is too low, artifacts may arise like \bokeh popping. If this number is too large, GPU memory usage is wasted. Thus, the right maximal number as to be set up according the type of scenes displayed.

%-------------------------------------------------------------------------------
\section{Conclusion}
We have presented an efficient implementation for rendering depth of field effect with \bokehs. This method allows to combine efficient blur-approach with \bokeh reproduction. We use an heuristic to identify pixels that produce distinct \bokeh and render them with textured quads. This implementation avoids CPU/GPU synchronization by calling indirect draw commands. These command read directly the number of instances to draw on GPU, without back reading from the CPU.


While this approach provides good results, several improvements could be done for improving performances. Especially, \codecmd{AtomicCounters} are not super fast. By dividing screen into four parts for example, each part having an atomic counter, would allow better scheduling. Large \coc size requires to rasterize quad on a large portion of the screen. Using the hierarchical rasterization, as proposed in~\cite{Futurmark11}, would also improve performances.



\begin{lstlisting}[language=C++,float={htb},caption={Host application for extracting \bokehs \emph{(Pass 2)}.},label={DeRousiers:bokehextractioncpp}]
		// Indirect buffer definition
		struct DrawArraysIndirectCommand
		{
			GLuint count;
			GLuint primCount;
			GLuint first;

			GLuint reservedMustBeZero;
		};

		// Create atomic counter
		GLuint indirectBufferID;
		glGenBuffers(1,&indirectBufferID);
		glBindBuffer(GL_DRAW_INDIRECT_BUFFER,indirectBufferID);
		DrawArraysIndirectCommand indirectCmd;
		indirectCmd.count              = 1;
		indirectCmd.primCount          = 1;
		indirectCmd.first              = 0;
		indirectCmd.reservedMustBeZero = 0;
		glBufferData(GL_DRAW_INDIRECT_BUFFER,sizeof(DrawArraysIndirectCommand),&indirecCmd,GL_DYNAMIC_DRAW);

		// Create a texture proxy for the indirect buffer 
		// (for using it as an atomic counter)
		glGenTextures(1, &bokehCountTexID);
		glBindTexture(GL_TEXTURE_BUFFER, bokehCountTexID);
		glTexBuffer(GL_TEXTURE_BUFFER, GL_R32UI, pointIndirectBuffer.id);

		// Create position and color textures with a GL_RGBA32F inner format
		...

		// Bind atomic counter
		glActiveTexture(GL_TEXTURE0 + bokehCountTexUnit);
		glBindTexture(GL_TEXTURE_BUFFER, bokehCountTexID);
		glBindImageTexture(bokehCountTexUnit,bokehCountTexID,0,false,0,GL_READ_WRITE,GL_R32UI);

		// Bind position image buffer
		glActiveTexture(GL_TEXTURE0 + bokehPosionTexUnit);
		glBindImageTexture(bokehPostionTexUnit,bokehPositionTex.id,0,false,0,GL_READ_WRITE,GL_RGBA32F);

		// Bind color image buffer
		glActiveTexture(GL_TEXTURE0 + bokehColorTexUnit);
		glBindImageTexture(bokehColorTexUnit,bokehColorTex.id,0,false,0,GL_READ_WRITE,GL_RGBA32F);

		DrawSceenQuad();
\end{lstlisting}


\begin{lstlisting}[language=GLSL,float={htb},caption={Fragment shader for extracting \bokehs \emph{(Pass 2)}.},label={DeRousiers:bokehextractionfs}]	
	#version 420
	// Bokeh counter, position (x,y,z,size), and color
	layout(size1x32) coherent uniform uimage1D 	BokehCountTex;
	layout(size4x32) coherent uniform  image1D 	BokehPositionTex;
	layout(size4x32) coherent uniform  image1D 	BokehColorTex;

	// Constrast threshold
	uniform float LumThreshold;
	...

	float sizeCenter; // Current CoC size
	vec3 colorCenter; // Current pixel color
	vec3 colorNeighs; // Average color of the neighborhood

	// Append pixel whose constrast is greater than the user's threshold
	float lumNeighs = dot(colorNeighs, vec3(0.299f, 0.587f, 0.114f));
	float lumCenter = dot(colorCenter, vec3(0.299f, 0.587f, 0.114f));
	if((lumCenter-lumNeighs)>LumThreshold)
	{
		int current = int(imageAtomicAdd(BokehCountTex, 1, 1));
		imageStore(BokehPositionTex,current,vec4(gl_FragCoord.x,gl_FragCoord.y,gl_FragCoord.z,sizeCenter));
		imageStore(BokehColorTex,current,vec4(colorCenter,1));
	}
\end{lstlisting}




\begin{lstlisting}[language=C++,float={htb},caption={Host application for rendering bokeh \emph{(Pass 4)}.},label={DeRousiers:renderingbokehcpp}]
	// Create point VBO
	GLuint pointVboID;
	glm::vec3 defaultPosition(0,0,0);
	glGenBuffers(1,&pointVboID);
	glBindBuffer(GL_ARRAY_BUFFER,pointVboID);
	glBufferData(GL_ARRAY_BUFFER,sizeof(glm::vec3),&defaultPosition,GL_STATIC_DRAW);

	// Create point VAO
	GLuint pointVaoID;
	glGenVertexArrays(1, &pointVaoID);
	glBindVertexArray(pointVaoID);
	glVertexAttribPointer(semantic::PositionLocation,3, GL_RGB,false,GL_FLOAT,GLF_BUFFER_OFFSET(_offset));
	glEnableVertexAttribArray(semantic::PositionLocation);
	glBindBuffer(GL_ARRAY_BUFFER, 0);
	glBindVertexArray(0);
	...

	// Wait for atomic counter synchronization and draw bokehs
	glMemoryBarrier(GL_ALL_BARRIER_BITS);
	glUseProgram(bokehRenderingProgramID);

	glActiveTexture(GL_TEXTURE0 + bokehShapeTexUnit);
	glBindTexture(GL_TEXTURE_1D,bokehShapeTexID);
	glActiveTexture(GL_TEXTURE0 + bokehColorTexUnit);

	glBindTexture(GL_TEXTURE_1D,bokehColorTexID);
	glActiveTexture(GL_TEXTURE0 + bokehPositionTexUnit);
	glBindTexture(GL_TEXTURE_1D,bokehPositionTexID);

	glBindVertexArray(pointVaoID);
		glBindBuffer(GL_DRAW_INDIRECT_BUFFER,indirectBufferID);
		glDrawArraysIndirect(GL_POINTS,NULL);
		glBindBuffer(GL_DRAW_INDIRECT_BUFFER,0);
	glBindVertexArray(0);
\end{lstlisting}


\begin{lstlisting}[language=C++,float={htb},caption={Pixel shader application for rendering bokeh \emph{(Pass 4)}.},label={DeRousiers:renderingbokehps}]
#version 420
uniform vec2      PixelScale;       // (1/xResolution,1/yResolution)
uniform sampler1D BokehPositionTex; // (x,y,z,scale)
uniform sampler1D BokehColorTex;
in vec3           Position;
out float         Radius;
out vec4          Color;

int main()
{
	vec3 pos     = texelFetch(BokehPositionTex,gl_InstanceID,0).xyzw;
	Radius       = pos.w;
	Color        = texelFetch(BokehColorTex,gl_InstanceID,0);
	gl_Position	 = vec4( (Position.xy+pos.xy)*PixelScale,pos.z,1);
}
\end{lstlisting}

\begin{lstlisting}[language=GLSL,float={htb},caption={Geometry shader for rendering bokeh \emph{(Pass 4)}.},label={DeRousiers:renderingbokehgs}]
#version 420
uniform mat4     Transformation;
uniform vec2     PixelScale;
in  float        Radius[1];
in  vec4         Color[1];
out vec4         Radiance;
out vec2         TexCoord;
layout(points)   in;
layout(triangle_strip, max_vertices = 6) out;

void main()
{
	gl_Layer     = 0;
	vec4 offsetx = vec4(PixelScale.x*Radius[0],0,0,0);
	vec4 offsety = vec4(0,PixelScale.y*Radius[0],0,0);
	Radiance     = Color[0];

	// First triangle
	gl_Position = Transformation*(gl_in[0].gl_Position-offsetx-offsety);
	TexCoord    = vec2(0,0);
	EmitVertex();
	gl_Position = Transformation*(gl_in[0].gl_Position+offsetx-offsety);
	TexCoord    = vec2(1,0);
	EmitVertex();
	gl_Position = Transformation*(gl_in[0].gl_Position+offsetx+offsety);
	TexCoord    = vec2(1,1);
	EmitVertex();
	EndPrimitive();
	// Second triangle
	...
}
\end{lstlisting}

%	gl_Position = Transformation*(gl_in[0].gl_Position-offsetx-offsety);
%	TexCoord    = vec2(0,0);
%	EmitVertex();
%	gl_Position = Transformation*(gl_in[0].gl_Position+offsetx+offsety);
%	TexCoord    = vec2(1,1);
%	EmitVertex();
%	gl_Position = Transformation*(gl_in[0].gl_Position-offsetx+offsety);
%	TexCoord    = vec2(0,1);
%	EmitVertex();
%	EndPrimitive();

\begin{lstlisting}[language=GLSL,float={htb},caption={Fragment shader for rendering bokeh \emph{(Pass 4)}.},label={DeRousiers:renderingbokehfs}]
#version 420
uniform sampler2D    BokehShapeTex; // Bokeh shape texture
uniform float        Attenuation;   // Factor for attenuating bokeh borders
in  vec4             Radiance;
in  vec2             TexCoord;
out vec4             FragColor;
void main()
{
	// Add an attenuation function in order to avoid hard edge on the 
	// aperture shape
	float val = textureLod(BokehShapeTex,TexCoord,0).x;
	float att = clamp(length(2.f*(TexCoord-vec2(0.5))),0.f,1.f);
	att       = 1.f - pow(att,Attenuation);
	FragColor = vec4(Radiance.xyz * val * att,Radiance.w);
}
\end{lstlisting}



%-------------------------------------------------------------------------------
\bibliographystyle{akpbib}
\bibliography{BokehRendering}











